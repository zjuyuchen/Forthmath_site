<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Chapter 1 概述</title>
</head>
<body>
<h1>统计学习</h1>
<p>
    <h3>1.1 统计学习就是计算机系统用数据和统计的方法提高系统性能的机器学习。</h3>
    <ol>
        <li>统计学的对象是数据</li>
        <li>基本假设是同类数据具有规律性</li>
        <li>目的是对数据进行预测和分析</li>
        <li>方法是构建数据模型对数据进行预测和分析</li>
        <ol>
            <li>Supervised learning</li>
            <li>Unsupervised learning</li>
            <li>semi-supervised learning</li>
            <li>reinforcement learning</li>
        </ol>
        <li>统计学习的步骤</li>
        <ol>
            <li>得到有限的数据集合</li>
            <li>得到包含可能模型的假设空间，即学习模型的集合</li>
            <li>确定模型选择的准则，也就是学习策略</li>
            <li>实现求解最优模型的方法，也就是算法</li>
            <li>通过学习算法选择最优模型</li>
            <li>用最优模型对数据进行分析和预测</li>
        </ol>
    </ol>
    <h3>1.2 监督学习</h3>
    <ol>
        <li>输入空间：输入的所有可能取值的集合</li>
        <li>输出空间：输出的所有可能取值的集合</li>
        <li>特征向量：每个输入时一个实例，用特征向量表示</li>
        <li>输入空间和输出空间都为连续变量的预测问题称为回归问题</li>
        <li>输出空间为有限个离散变量的预测问题称为分类问题</li>
        <li>输入空间和输出空间都是变量序列的预测问题称为标注问题</li>
        <li>输入和输出遵循联合概率分布P（X, Y）</li>
        <li>由输入到输出的映射的集合称为假设空间，也就是学习模型的集合</li>
    </ol>
    <h3>1.3 统计学习三要素</h3>
    <ol>
        <li>方法 = 模型 + 策略 + 算法</li>
        <li>模型：所要学习的条件概率分布过着决策函数</li>
        <li>策略：损失函数和风险函数</li>
        <ol>
            <li>损失函数是f(X)和Y的非负函数：L（f(x), Y）</li>
            <li>常见的损失函数有：</li>
            <ul>
                <li>0-1损失函数</li>
                <li>平方损失函数</li>
                <li>绝对损失函数</li>
                <li>对数损失函数</li>
            </ul>
            <li>损失函数越小，模型就越好</li>
            <li>经验风险：关于数据集的平均损失称为经验风险</li>
            <li>结构风险：经验风险加上正则化项</li>
            <li>正则化项：模型的复杂度，结构风险的目的是惩罚复杂模型，降低模型复杂度</li>
        </ol>
        <li>算法：学习模型的具体算法</li>
    </ol>
    <h3>1.4 模型评估与模型选择</h3>
    <ol>
        <li>训练误差：损失函数给定后，关于训练集的平均误差</li>
        <li>测试误差：损失函数给定后，关于测试集的平均误差</li>
        <li>过拟合：一味地降低训练误差，导致所选模型比真实模型复杂度高,测试误差变高</li>
        <li>模型选择方法：</li>
        <ol>
            <li>正则化</li>
            <li>交叉验证</li>
        </ol>
    </ol>
    <h3>1.5 正则化和交叉验证</h3>
    <ol>
        <li>结构风向中的第一项是经验风险，第二项是正则化项</li>
        <li>经验风险可能会导致模型复杂度高</li>
        <li>正则化项是用来降低复杂度</li>
        <li>奥卡姆剃刀原理：在所有可能选择的模型里面，能够很好的解释已知数据，并且十分简单才是最好的模型！</li>
        <li>交叉验证：对给定的训练集进行切分，切分为训练集和测试集，在此基础上反复进行训练、测试和模型选择</li>
        <li>交叉验证常用方法：</li>
        <ul>
            <li>简单交叉验证：随机将数据分为两部分</li>
            <li>S折交叉验证：数据集切割为S个子集，用S-1个进行训练，剩下的进行测试。对每种选择（共S个）进行重复</li>
            <li>留一法：S折交叉的极限，子集中只包含一个数据</li>
        </ul>
    </ol>
    <h3>1.6 泛化能力</h3>
    <ol>
        <li>泛化能力：是指学习到的模型对未知数据的预测能力</li>
        <li>最常用的方法是：用测试数据集评价泛化能力</li>
        <li>测试数据集有限，所以得出的泛化能力是不可靠的</li>
        <li>泛化误差上界：通常对比模型优劣实际采用的对象</li>
        <ul>
            <li>样本容量增加，泛化上界趋于0</li>
            <li>假设空间越大，模型越难学，泛化上界越大</li>
        </ul>
    </ol>
    <h3>1.7 生成模型和判别模型</h3>
    <ol>
        <li>模型一般形式为：</li>
        <ul>
            <li>决策函数：Y=f(x)</li>
            <li>条件概率分布：P（Y|X）,给定特征X的情况下估计是Y的概率分布</li>
        </ul>
        <li>生成模型：模型表示了给定输入X，产生输出Y的生成关系</li>
        <ul>
            <li>朴素贝叶斯法</li>
            <li>隐马尔科夫模型</li>
        </ul>
        <li>判别模型：由数据直接学习决策函数f(x)或者P（Y|X）作为预测模型</li>
        <ul>
            <li>k近邻法</li>
            <li>感知机</li>
            <li>决策树</li>
            <li>Logistic 回归</li>
            <li>最大熵模型</li>
            <li>SVM支持向量机</li>
            <li>提升方法和条件随机场</li>
        </ul>
        <li>优缺点</li>
        <ul>
            <li>生成方法可以还原概率分布，判别方法不行</li>
            <li>生成方法收敛速度快，样本量增加，迅速收敛到真实模型</li>
            <li>含有隐变量时仍能够使用，判别方法不行</li>
            <li>判别方法，直接面对预测，准确度高</li>
            <li>由于直接学习模型，所以可以简化学习问题</li>
        </ul>
    </ol>
    <h3>1.8 分类问题</h3>
    <ol>
        <li>多分类问题</li>
        <li>评价指标是准确率accuracy: 给定分类器，正确分类的样本和总样本的比例</li>
        <li>二分类问题常用评价体系：</li>
        <li>先做以下定义：</li>
        <ul>
            <li>TP: 正例预测为正</li>
            <li>FP: 负例预测为正</li>
            <li>TN: 负例预测为负</li>
            <li>FN: 正例预测为负</li>
        </ul>
        <li>精确率precision：</li>
        <li>P = TP/(TP+FP) : 预测正结果中真正例所占比例</li>
        <li>召回率recall</li>
        <li>R = TP/(TP+FN): 所有正例中被预测为正所占比例</li>
        <li>F1值是P和R的调和平均：目的是让准确率和召回率都比较高</li>
    </ol>
    <h3>1.9 标注问题</h3>
    <ol>
        <li>主要使用领域：信息抽取、自然语言处理</li>
        <li>学习方法有：隐马尔科夫模型、条件随机场</li>
    </ol>
    <h3>1.10 回归问题</h3>
    <ol>
        <li>回归问题等价于函数拟合</li>
        <li>常用的损失函数是平方损失函数</li>
        <li>也就是最小二乘法</li>
    </ol>
</p>
</body>
</html>