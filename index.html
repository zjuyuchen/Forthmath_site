<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ForthMath</title>
    <style>
        div{ margin: auto; width: 80%}
        ol li {list-style-type:none;  text-align:center;}
        h1 {color: crimson}
        h2 {color: white; background-color: #75736e; text-align: left; width: 100%}
        #索引 p {text-align:center;font-size: larger}
    </style>
</head>
<body >
<div>
    <h1 style="text-align: center">写在前面的话</h1>
    <p>随着信息传输速度的不断提升，我们能够获取的数据也指数地增长。近两年来，大数据分析和机器学习方向研究和从业也水涨船高。
        尤其最近，谷歌公司的Alpha Go, Alpha Go zero等深度学习项目取得了突破的进展，吸足了大众的目光。隐隐让人们产生了
        一种机器学习会促使发生工业革命的感觉。的确，自动驾驶、人脸识别、自然语言处理这些项目上让人们看到了生产力进一步提
        高的潜力，勾画了未来十几年的美好蓝图。但是，机器学习仍然存在一些问题以及将要面临的问题,比如当前很火的深度学习。如果
        模型进一步复杂下去，参数之间的相互作用越来越强，是否会变成物理中多体问题一样，只能通过宏观上的统计量或者各种简化条件
        的假设去进行模型的设计？本质上来说，人工智能理论上近些年来没有明显的突破，它的发展还是依托于数据和计算能力。将来，模
        型越复杂，对计算能力的要求越高，在量子计算没有得到实用性突破的情况下，未来几年内是否会面临瓶颈？我想，这些决定发展前
        景的问题值得每一个试图进入这个行业的人思考。<br>
        未来的机器学习发展，会和量子计算的实现将牢不可分。令人振奋的是，最近两年来，国内国外在量子计算方法都取得了不错的
        进展。比如国内潘建伟领导的10个纠缠的超导量子比特的实现，未来几年内达到50个纠缠量子比特的宏伟目标。这些都让人对机器学习
        的未来充满期待。也让人们对未来二十年科技和生活方式的发展充满憧憬！！！<br>
        最后，希望在我知天命之年，可控核聚变得以实现，量子计算蓬勃发展，行星际旅行成为家常便饭，普通人也可以乘坐自动驾驶汽车在
        火星的城市里驰骋！
    </p>
</div>
<div id="索引">
    <h1 style="text-align: center">索引</h1>
    <p>实验相关工具</p>
    <p><a href="#Experimental tools">Experimental data analysis tools</a></p>
    <br>
    <p>大数据&机器学习资源</p>
    <p><a href="#思维导图">思维导图</a></p>
    <p><a href="#数学基础">数学基础</a></p>
    <p><a href="#Python资源汇总">Python资源汇总</a></p>
    <p><a href="#cheat sheets">Big data cheat sheets</a></p>
    <p><a href="File/Tutorial_HYLee_Deep.pdf">一天看懂Deep Learning</a></p>
    <p><a href="http://speech.ee.ntu.edu.tw/~tlkagk/index.html">李宏毅个人主页</a></p>
    <br>
    <p>学习笔记</p>
    <p><a href="#ISL">An introduction to statistic learning</a></p>
    <p><a href="#统计学习方法">统计学习方法</a></p>
    <br>
    <p>很好的博客和网址</p>
    <p><a href="#Good blogs">Good blogs</a></p>
    <br>
    <p>其它</p>
    <p><a href="#other">Other</a></p>
</div>

<div id="Experimental tools">
    <h2>Experimental data analysis tools</h2>
    <ul>
        <a href="Oscillations%20analysis.html"><li>Oscillation analysis</li></a>
    </ul>

</div>
<div id="Good blogs">
    <h2>一些非常好的博客</h2>
    <ul>
        <li><a href="http://blog.csdn.net/zouxy09/article/details/24971995">范数规则化：L0，L1， L2</a></li>
    </ul>
</div>
<div id="数学基础">
    <h2>数学基础</h2>
    <ul>
        <li><a href="Source/Math/cs229-linalg.pdf">线性代数Stanford cs229</a></li>
        <p>内容我浏览了一遍，非常适合机器学习基础线代基础较弱的（比如我）的同学，只有26页，内容详实简单，很快就可以看完。</p>
        <li><a href="http://cs229.stanford.edu/syllabus.html">Machine Learning - Stanford cs229</a></li>
    </ul>
    <h2>笔记</h2>
    <ul>
        <li><a href="Source/Notes/PCA主成分分析.html">PCA主成分分析</a></li>
    </ul>
</div>
<div id="思维导图">
    <h2>思维导图</h2>
    <ul>
        <li><a href="back.png">机器学习脑图</a></li>
    </ul>
    <p>Thanks <a href="https://www.zhihu.com/people/HANGZS/activities">zhenhang.sun</a></p>
    <ul>
        <li><a href="File/pic_math0.png">数学分析</a></li>
        <li><a href="File/pic_math.png">概率论与数理统计</a></li>
        <li><a href="File/pic_data.png">大数据之路</a></li>
    </ul>
</div>
<div id="Readbooks">
    <h2>Read book online</h2>
    <ul>
        <li><a href="File/An+Introduction+to+Statistical+Learning.pdf">An introduction to statistic learning (9M)</a></li>
    </ul>
</div>
<div id="Python资源汇总">
    <h2>Python资源汇总</h2>
    <p>下面资源总结于知乎 <a href="https://zhuanlan.zhihu.com/p/25761248">机器之心</a>，非常全面</p>
    <p>内容选自选自Kdnuggets <a href="https://www.kdnuggets.com/2015/11/seven-steps-machine-learning-python.html">1</a> <a href="https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html/2">2</a>，机器之心编译</p>
    <p><a href="https://www.kdnuggets.com/2016/05/machine-learning-key-terms-explained.html">机器学习关键术语</a></p>
    <h4>如果你不想系统地学习机器学习理论知识，想稍微了解理论后迅速上手的话下面的资源就够了</h4>
    <ul>
        <li><a href="http://www.holehouse.org/mlclass/">吴恩达机器学习非官方笔记</a></li>
        <li><a href="http://www.scipy-lectures.org/">Scipy Lecture Notes</a></li>
        <li><a href="http://pandas.pydata.org/pandas-docs/stable/10min.html">10 mins to Pandas</a></li>
        <h4>官方文档链接</h4>
        <li><a href="http://scikit-learn.org/stable/">Scikit-learn</a></li>
        <li><a href="http://www.numpy.org/">Numpy</a></li>
        <li><a href="http://pandas.pydata.org/">Pandas</a></li>
        <li><a href="http://matplotlib.org/">Matplotlib</a></li>
        <h4>IPython-Jupyter tutorials</h4>
        <li><a href="http://cs231n.github.io/ipython-tutorial/">Stanford IPython tutorials</a></li>
        <li><a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/tree/master/">scikit-learn 简介</a></li>
        <p>下面这个教程打开后最下面有很多Python的资源链接，包括Machine learning free books等等</p>
        <li><a href="http://nbviewer.jupyter.org/github/rhiever/Data-Analysis-and-Machine-Learning-Projects/blob/master/example-data-science-notebook/Example%20Machine%20Learning%20Notebook.ipynb">Randal Olson 的机器学习案例笔记</a></li>
        <li><a href="https://github.com/justmarkham/scikit-learn-videos/blob/master/05_model_evaluation.ipynb">Kevin Markham 的模型评估</a></li>
        <h4>熟悉Scikit-learn之后进阶</h4>
        <li><a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb">线性回归</a></li>
        <li><a href="https://github.com/jakevdp/sklearn_pycon2015/blob/master/notebooks/04.2-Clustering-KMeans.ipynb">K-均值聚类</a></li>

        <li><a href="http://thegrimmscientist.com/tutorial-decision-trees/">决策树</a></li>
        <li><a href="https://github.com/justmarkham/gadsdc/blob/master/logistic_assignment/README.md">Logistic regression</a></li>
        <li><a href="https://github.com/jakevdp/sklearn_pycon2015/blob/master/notebooks/03.1-Classification-SVMs.ipynb">支持向量机</a></li>
        <li><a href="http://nbviewer.jupyter.org/github/donnemartin/data-science-ipython-notebooks/blob/master/kaggle/titanic.ipynb">随机森林</a></li>
        <li><a href="https://github.com/jakevdp/sklearn_pycon2015/blob/master/notebooks/04.1-Dimensionality-PCA.ipynb">降维算法</a></li>
        <h4>非Jupyter的Python编写内容-完成上一步再进行</h4>
        <li><a href="http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html">文档分类</a></li>
        <li><a href="https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/">k-最近邻分类</a></li>
        <li><a href="http://scikit-learn.org/stable/modules/neural_networks_supervised.html">神经网络模型（监督式）</a></li>
        <li><a href="https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html">神经网络初学者指南</a></li>
        <li><a href="https://www.kdnuggets.com/2016/09/comparing-clustering-techniques-concise-technical-overview.html">聚类技术比较</a></li>
        <li><a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html">玩具数据集中比较不同的聚类算法</a></li>
        <li><a href="https://www.kdnuggets.com/2016/08/tutorial-expectation-maximization-algorithm.html">期望最大化（EM）算法教程</a></li>
        <li><a href="http://scikit-learn.org/stable/modules/mixture.html">高斯混合模型</a></li>
        <li><a href="http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/"> Python 构建高斯混合模型</a></li>
        <h4>集成学习器</h4>
        <li><a href="https://www.kdnuggets.com/2016/11/data-science-basics-intro-ensemble-learners.html">集成学习器介绍</a></li>
        <li><a href="http://scikit-learn.org/stable/modules/ensemble.html">Scikit-learn 中的集成方法</a></li>
        <li><a href="https://www.kdnuggets.com/2016/12/random-forests-python.html">Python中随机森林</a></li>
        <h4>梯度提升</h4>
        <li><a href="https://jessesw.com/XG-Boost/">Python 中 XGBoost 梯度提升树的实现指南</a></li>
        <li><a href="https://www.kaggle.com/cbrogan/titanic/xgboost-example-python">XGBoost 在 Kaggle 上的示例（Python）</a></li>
        <h4>主成分分析（PCA）</h4>
        <li><a href="http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html">Sebastian Raschka 3步法</a></li>
        <li><a href="http://sebastianraschka.com/Articles/2014_python_lda.html">线性判别分析LDA</a></li>
        <li><a href="https://sebastianraschka.com/faq/docs/lda-vs-pca.html">PCA, LDA区别</a></li>
        <h4>深度学习，我推荐使用Tensorflow和Keras</h4>
        <li>莫凡Tensorflow教程</li>
        <li>Sentdex教程</li>
    </ul>
</div>
<div id="cheat sheets">
    <h2>Big data cheat sheet</h2>
    <ul>
        <a href="https://www.dataquest.io/blog/numpy-cheat-sheet/"><li>Numpy cheat sheet</li></a>
        <a href=File/pandas-cheat-sheet.pdf><li>Numpy cheat sheet pdf version</li></a>
        <a href="https://www.dataquest.io/blog/pandas-cheat-sheet/"><li>Pandas cheat sheet</li></a>
        <a href=File/pandas-cheat-sheet.pdf><li>Pandas cheat sheet paf version</li></a>
        <a href="http://scikit-learn.org/stable/tutorial/machine_learning_map/"><li>Scikit learn ML map</li></a>
        <a href=File/ml_map.png><li>Scikit learn ML map PNG version</li></a>
        <li><a href="https://pan.baidu.com/s/1eSgn81G#list/path=%2F">zhenhan.sun's book list</a> ps: fe0k</li>
    </ul>
    <h2>Cheat sheets for ML</h2>
    <p>原文地址是：<a href="https://link.zhihu.com/?target=https%3A//unsupervisedmethods.com/cheat-sheet-of-machine-learning-and-python-and-math-cheat-sheets-a4afe4e791b6">Cheat Sheet of Machine Learning and Python (and Math) Cheat Sheets</a></p>
    <ul>
        <li><a href="File/python_cheat_1page.pdf">Python 1 page</a></li>
        <li><a href="File/python_cheat.pdf">Python 2 pages</a></li>
        <li><a href="File/jupyter_cheat.pdf">Jupyter notebook</a></li>
        <li><a href="File/numpy_cheat.pdf">Numpy 1</a></li>
        <li><a href="File/numpy_cheat_02.pdf">Numpy 2</a></li>
        <li><a href="File/pandas_cheat.png">Pandas 1</a></li>
        <li><a href="File/pandas_cheat.pdf">Pandas 2</a></li>
        <li><a href="File/Python_Matplotlib_Cheat_Sheet.pdf">Matplotlib</a></li>
        <li><a href="File/seaborn_cheat.pdf">Seaborn</a></li>
        <li><a href="File/scipy_cheat.pdf">Scipy</a></li>
        <li><a href="File/scikit_cheat.pdf">Scikit learn</a></li>
        <li><a href="File/pyspark_cheat.pdf">Pyspark</a></li>
        <li><a href="File/keras_cheat.pdf">Keras</a></li>
        <li><a href="File/Calculus_Cheat_Sheet_All_Reduced.pdf">Calculus</a></li>
        <li><a href="File/stats_handout.pdf">Statistic</a></li>
        <li><a href="File/machine-learning-cheet-sheet.png">Machine learning</a></li>
        <li><a href="File/regression%20or%20categorized.jpg">Regression</a></li>
        <li><a href="File/neuralnetworks.png">Neural network</a></li>
        <li><a href="File/microsoft-machine-learning-algorithm-cheat-sheet-v6.pdf">Algorithms</a></li>


    </ul>
</div>
<div id="ISL">
    <h2>An introduction to statistic learning Notes of YC</h2>
    <ul>
        <h3><b>2</b></h3>
        <b>2.1</b>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.1.1.html">2.1.1</a></li>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.1.2.html">2.1.2</a></li>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.1.3.html">2.1.3</a></li>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.1.4.html">2.1.4</a></li>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.1.5.html">2.1.5</a></li>
        <b>2.2</b>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.2.1.html">2.2.1</a></li>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.2.2.html">2.2.2</a></li>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.2.3.html">2.2.3</a></li>
        <b>2.3</b>
        <li><a href="File/ISL/An%20introduction%20to%20statistic%20learning%202.3.html">2.3</a></li>
        <b>3</b>
        <li><a href=""></a></li>
    </ul>
</div>
<div id="统计学习方法">
    <h2>统计学习方法-李航 Notes</h2>
    <ul>
        <li><a href="File/统计学习方法/Notes/Chapter1.html">第一章、统计学习方法</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter2.html">第二章、感知机</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter3.html">第三章、k近邻法</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter4.html">第四章、朴素贝叶斯法</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter5.html">第五章、决策树</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter6.html">第六章、Logistic回归方法</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter7.html">第七章、支持向量机（SVM）</a></li>
        <li><a href="File/统计学习方法/Notes/Chapter8.html">第八章、提升算法(Boost)</a></li>
		<p>卡在EM算法两三天了，统计学习方法中个人觉得关于EM讲的并不好，吴恩达的课程相对容易理解一点。EM算法，后面的隐马尔科夫以及条件随机平时见到的比较少，就暂时不写了，等以后有需要了补上。</p>
    </ul>
</div>
<div id="other">
    <h2>Other</h2>
    <ul>
        <a href="http://www.runoob.com/html/html-quicklist.html"><li>HTML 速查列表</li></a>
        <li><a href="http://blog.leanote.com/post/freewalk/Markdown-%E8%AF%AD%E6%B3%95%E6%89%8B%E5%86%8C">Markdown 语法手册</a></li>
        <li><a href="Source/Other/Git_cheat_sheet.html">Git Cheat Sheet</a></li>
        <li><a href="http://www.cheat-sheets.org/">All cheat sheet in one page</a></li>
        <li><a href="http://blog.csdn.net/ws_20100/article/details/49159291">Latex数学符号表示</a></li>
    </ul>
</div>
</body>
</html>